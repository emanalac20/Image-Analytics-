{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e45c0c-bff6-49b9-b338-3029d32f6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code detects objects using Faster RCNN\n",
    "#You may need to install the following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92ab79-637a-4e1c-88e3-b48b8821dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506aa8ba-ae6b-4d1f-839b-dc6f11266f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.models.detection as detection\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548b8c6-7e5f-42be-b236-55211b86e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use the pre-trained FasterRCNN_ResNet50_FPN model. This model is trained with the COCO dataset\n",
    "#Let us see the COCO dataset classes. These classes will be printed in the image\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN_ResNet50_FPN_Weights\n",
    "\n",
    "# Load the metadata for the pre-trained model\n",
    "weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "COCO_CLASSES = weights.meta[\"categories\"]  # Fetch the class names dynamically\n",
    "\n",
    "print(COCO_CLASSES) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beba7d4-9aab-40c1-89f4-343e2d843549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the pre-trained Faster R-CNN model\n",
    "model = detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Load the image\n",
    "image_path = \"195.jpg\"\n",
    "image = Image.open(image_path)\n",
    "# Convert the image to a tensor in the C (channels), H (height), and W (weight)\n",
    "image_tensor = F.to_tensor(image) #Converts the input image (loaded using PIL) into a tensor format required by PyTorch models.\n",
    "\n",
    "\n",
    "# Step 3: Perform object detection\n",
    "with torch.no_grad():\n",
    "    predictions = model([image_tensor])\n",
    "\n",
    "# Step 4: Extract predictions\n",
    "predicted_boxes = predictions[0]['boxes']  # Bounding boxes\n",
    "predicted_scores = predictions[0]['scores']  # Confidence scores\n",
    "predicted_labels = predictions[0]['labels']  # Class indices\n",
    "\n",
    "#Filter predictions by confidence threshold. Let us assume that we are only interested in those prediction which are above 0.5\n",
    "confidence_threshold = 0.5\n",
    "filtered_boxes = []\n",
    "filtered_scores = []\n",
    "filtered_labels = []\n",
    "\n",
    "for box, score, label in zip(predicted_boxes, predicted_scores, predicted_labels):\n",
    "    if score >= confidence_threshold:\n",
    "        filtered_boxes.append(box)\n",
    "        filtered_scores.append(score)\n",
    "        filtered_labels.append(label)\n",
    "\n",
    "# Step 5: Annotate the image with bounding boxes and class names\n",
    "fig, ax = plt.subplots(1, figsize=(12, 8), dpi=72)  # Set the figure size and resolution\n",
    "ax.imshow(image)\n",
    "\n",
    "for box, score, label in zip(filtered_boxes, filtered_scores, filtered_labels):\n",
    "    x_min, y_min, x_max, y_max = box.tolist()\n",
    "    class_name = COCO_CLASSES[label.item()]  # Map label to class name\n",
    "\n",
    "    # Draw the bounding box\n",
    "    rect = patches.Rectangle(\n",
    "        (x_min, y_min),\n",
    "        x_max - x_min,\n",
    "        y_max - y_min,\n",
    "        linewidth=2,\n",
    "        edgecolor='red',\n",
    "        facecolor='none'\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Add the class name and score as text\n",
    "    ax.text(\n",
    "        x_min,\n",
    "        y_min - 5,\n",
    "        f\"{class_name}: {score:.2f}\",\n",
    "        color='white',\n",
    "        fontsize=10,\n",
    "        bbox=dict(facecolor='red', alpha=0.5)\n",
    "    )\n",
    "\n",
    "plt.axis(\"off\")  # Hide axes for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83989493-8f54-488c-b8fe-b47f8db3b618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
